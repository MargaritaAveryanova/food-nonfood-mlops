import os
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import cv2
from utils import load_params, setup_mlflow_experiment_safe
import mlflow

def load_and_preprocess_data(data_path: str, img_size: tuple = (224, 224)):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    categories = ['food', 'non_food']
    images = []
    labels = []
    
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    for label, category in enumerate(categories):
        category_path = os.path.join(data_path, category)
        if not os.path.exists(category_path):
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {category_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
            continue
            
        image_files = [f for f in os.listdir(category_path) 
                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not image_files:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≤ {category_path} –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")
            continue
            
        for img_file in image_files:
            img_path = os.path.join(category_path, img_file)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            img = cv2.imread(img_path)
            if img is not None:
                img = cv2.resize(img, img_size)
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img = img.astype(np.float32) / 255.0
                
                images.append(img)
                labels.append(label)
    
    if len(images) == 0:
        raise ValueError("–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º.")
    
    return np.array(images), np.array(labels)

def create_data_generators(X_train, y_train, X_val, y_val, batch_size: int = 32):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π"""
    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        horizontal_flip=True,
        zoom_range=0.2,
        brightness_range=[0.8, 1.2]
    )
    
    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator()
    
    train_generator = train_datagen.flow(
        X_train, y_train,
        batch_size=batch_size,
        shuffle=True
    )
    
    val_generator = val_datagen.flow(
        X_val, y_val,
        batch_size=batch_size,
        shuffle=False
    )
    
    return train_generator, val_generator

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    params = load_params()
    data_params = params['data']
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
    try:
        experiment_id = setup_mlflow_experiment_safe()
        if experiment_id:
            with mlflow.start_run(run_name="data_preprocessing"):
                mlflow.log_params({
                    "image_size": data_params['image_size'],
                    "batch_size": data_params['batch_size'],
                    "validation_split": data_params['validation_split']
                })
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                data_path = "data/raw"
                X, y = load_and_preprocess_data(data_path, tuple(data_params['image_size']))
                
                # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/validation/test
                X_temp, X_test, y_temp, y_test = train_test_split(
                    X, y, 
                    test_size=data_params['test_split'], 
                    random_state=42, 
                    stratify=y
                )
                
                X_train, X_val, y_train, y_val = train_test_split(
                    X_temp, y_temp,
                    test_size=data_params['validation_split'],
                    random_state=42,
                    stratify=y_temp
                )
                
                # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
                os.makedirs("data/processed/train", exist_ok=True)
                os.makedirs("data/processed/validation", exist_ok=True)
                os.makedirs("data/processed/test", exist_ok=True)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                np.save("data/processed/train/X_train.npy", X_train)
                np.save("data/processed/train/y_train.npy", y_train)
                np.save("data/processed/validation/X_val.npy", X_val)
                np.save("data/processed/validation/y_val.npy", y_val)
                np.save("data/processed/test/X_test.npy", X_test)
                np.save("data/processed/test/y_test.npy", y_test)
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞–Ω–Ω—ã—Ö
                mlflow.log_metrics({
                    "train_samples": len(X_train),
                    "validation_samples": len(X_val),
                    "test_samples": len(X_test),
                    "food_ratio_train": float(np.mean(y_train)),
                    "food_ratio_test": float(np.mean(y_test))
                })
                
                print(f"–î–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
                print(f"  Train: {len(X_train)} samples")
                print(f"  Validation: {len(X_val)} samples")
                print(f"  Test: {len(X_test)} samples")
        else:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å MLflow")
            
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ MLflow: {e}")
        print("üîß –ó–∞–ø—É—Å–∫ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–µ–∑ MLflow...")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ MLflow
        data_path = "data/raw"
        X, y = load_and_preprocess_data(data_path, tuple(data_params['image_size']))
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/validation/test
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, 
            test_size=data_params['test_split'], 
            random_state=42, 
            stratify=y
        )
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp,
            test_size=data_params['validation_split'],
            random_state=42,
            stratify=y_temp
        )
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        os.makedirs("data/processed/train", exist_ok=True)
        os.makedirs("data/processed/validation", exist_ok=True)
        os.makedirs("data/processed/test", exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        np.save("data/processed/train/X_train.npy", X_train)
        np.save("data/processed/train/y_train.npy", y_train)
        np.save("data/processed/validation/X_val.npy", X_val)
        np.save("data/processed/validation/y_val.npy", y_val)
        np.save("data/processed/test/X_test.npy", X_test)
        np.save("data/processed/test/y_test.npy", y_test)
        
        print(f"–î–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print(f"  Train: {len(X_train)} samples")
        print(f"  Validation: {len(X_val)} samples")
        print(f"  Test: {len(X_test)} samples")

def run_preprocessing_without_mlflow(params):
    """–ó–∞–ø—É—Å–∫ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–µ–∑ MLflow"""
    data_params = params['data']
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    data_path = "data/raw"
    X, y = load_and_preprocess_data(data_path, tuple(data_params['image_size']))
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/validation/test
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, 
        test_size=data_params['test_split'], 
        random_state=42, 
        stratify=y
    )
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp,
        test_size=data_params['validation_split'],
        random_state=42,
        stratify=y_temp
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    os.makedirs("data/processed/train", exist_ok=True)
    os.makedirs("data/processed/validation", exist_ok=True)
    os.makedirs("data/processed/test", exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    np.save("data/processed/train/X_train.npy", X_train)
    np.save("data/processed/train/y_train.npy", y_train)
    np.save("data/processed/validation/X_val.npy", X_val)
    np.save("data/processed/validation/y_val.npy", y_val)
    np.save("data/processed/test/X_test.npy", X_test)
    np.save("data/processed/test/y_test.npy", y_test)
    
    print(f"–î–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"  Train: {len(X_train)} samples")
    print(f"  Validation: {len(X_val)} samples")
    print(f"  Test: {len(X_test)} samples")

if __name__ == "__main__":
    main()