import mlflow
import mlflow.tensorflow
import yaml
import tensorflow as tf
import json
import os

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥ –∑–¥–µ—Å—å
class Config:
    RAW_DATA_PATH = "data/raw"
    PROCESSED_DATA_PATH = "data/processed"
    MODELS_PATH = "models"
    IMG_HEIGHT = 224
    IMG_WIDTH = 224
    BATCH_SIZE = 32
    EPOCHS = 5
    VALIDATION_SPLIT = 0.2
    RANDOM_SEED = 42

def create_simple_cnn(input_shape=(224, 224, 3)):
    from tensorflow.keras import layers, models
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

def create_data_generators():
    import tensorflow as tf
    import os
    
    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        validation_split=Config.VALIDATION_SPLIT
    )
    
    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        validation_split=Config.VALIDATION_SPLIT
    )
    
    train_generator = train_datagen.flow_from_directory(
        os.path.join(Config.RAW_DATA_PATH, 'training'),
        target_size=(Config.IMG_HEIGHT, Config.IMG_WIDTH),
        batch_size=Config.BATCH_SIZE,
        class_mode='binary',
        subset='training',
        seed=Config.RANDOM_SEED
    )
    
    val_generator = val_datagen.flow_from_directory(
        os.path.join(Config.RAW_DATA_PATH, 'training'),
        target_size=(Config.IMG_HEIGHT, Config.IMG_WIDTH),
        batch_size=Config.BATCH_SIZE,
        class_mode='binary',
        subset='validation',
        seed=Config.RANDOM_SEED
    )
    
    print(f"‚úÖ Training samples: {train_generator.samples}")
    print(f"‚úÖ Validation samples: {val_generator.samples}")
    return train_generator, val_generator

def train():
    print("üöÄ Starting model training...")
    
    with open('params.yaml', 'r') as f:
        params = yaml.safe_load(f)
    
    mlflow.set_experiment("food_classification")
    
    with mlflow.start_run():
        mlflow.log_params(params['data'])
        mlflow.log_params(params['training'])
        mlflow.log_param("model_type", params['model']['type'])
        
        train_gen, val_gen = create_data_generators()
        
        if params['model']['type'] == 'simple_cnn':
            model = create_simple_cnn()
            print("‚úÖ Simple CNN model created")
        else:
            raise ValueError(f"Unknown model type: {params['model']['type']}")
        
        mlflow.tensorflow.autolog()
        
        print("üìö Training model...")
        history = model.fit(
            train_gen,
            epochs=params['training']['epochs'],
            validation_data=val_gen,
            verbose=1
        )
        
        os.makedirs(Config.MODELS_PATH, exist_ok=True)
        model_path = os.path.join(Config.MODELS_PATH, 'food_classifier.h5')
        model.save(model_path)
        mlflow.log_artifact(model_path)
        
        final_accuracy = history.history['val_accuracy'][-1]
        
        train_metrics = {
            "train_accuracy": float(history.history['accuracy'][-1]),
            "train_loss": float(history.history['loss'][-1]),
            "val_accuracy": float(final_accuracy),
            "val_loss": float(history.history['val_loss'][-1])
        }
        
        with open('train_metrics.json', 'w') as f:
            json.dump(train_metrics, f, indent=2)
        
        mlflow.log_metric("val_accuracy", final_accuracy)
        
        print(f"‚úÖ Training completed! Final accuracy: {final_accuracy:.4f}")

if __name__ == "__main__":
    train()